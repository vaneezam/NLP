{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 02-Named Entity Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhykLGDuLkyP"
      },
      "source": [
        "# **Named Entity Recognition** using:\n",
        "\n",
        "\n",
        "1.   Tokenize -> Chunk and Parse -> IOB Tagging -> Classifier(ne_chunk)\n",
        "2.   SpaCy (fast and accurate) <br><br>\n",
        "Reference: https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc-F5s8iZsy5"
      },
      "source": [
        "##**1) Tokenize -> Chunk and Parse -> IOB Tagging -> Classifier(ne_chunk)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4g34P0QL1WN"
      },
      "source": [
        "\n",
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZsXWsf6Lnsp",
        "outputId": "b5b5bca6-872c-4ac0-85e8-2ded74e235fe"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpRMYyZBMWf1"
      },
      "source": [
        "**Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi85APDwMYiy"
      },
      "source": [
        "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGYIQ1WNM-aZ"
      },
      "source": [
        "**Preprocessing: Tokenize and Identify part of speech**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXnwOCpuNEcZ"
      },
      "source": [
        "def preprocess(sent):\n",
        "    sent = nltk.word_tokenize(sent)\n",
        "    sent = nltk.pos_tag(sent) #part of speech tagging (JJ-Adjective, NNS-Noun,plural, VBD-Verb,pasttense etc.) -> https://pythonspot.com/nltk-speech-tagging/\n",
        "    return sent"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c1kUTtDNTxd",
        "outputId": "974308d7-a41d-4ee9-ab54-bcf782b94efb"
      },
      "source": [
        "sent = preprocess(ex)\n",
        "sent"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('European', 'JJ'),\n",
              " ('authorities', 'NNS'),\n",
              " ('fined', 'VBD'),\n",
              " ('Google', 'NNP'),\n",
              " ('a', 'DT'),\n",
              " ('record', 'NN'),\n",
              " ('$', '$'),\n",
              " ('5.1', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('on', 'IN'),\n",
              " ('Wednesday', 'NNP'),\n",
              " ('for', 'IN'),\n",
              " ('abusing', 'VBG'),\n",
              " ('its', 'PRP$'),\n",
              " ('power', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('mobile', 'JJ'),\n",
              " ('phone', 'NN'),\n",
              " ('market', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('ordered', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('company', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('alter', 'VB'),\n",
              " ('its', 'PRP$'),\n",
              " ('practices', 'NNS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5Uk0Va5R1Fu"
      },
      "source": [
        "**Chunk and Parse**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgRWSLQwR48Q",
        "outputId": "756f83ad-d457-49e7-f703-91849934136a"
      },
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "cp = nltk.RegexpParser(pattern)\n",
        "cs = cp.parse(sent) \n",
        "#Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure -\n",
        "# that reveals the relationships between tokens governed by syntax rules, e.g. by grammars\n",
        "#EXAMPLE 'a record' is parsed -> tree structure created\n",
        "print(cs)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  European/JJ\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  Google/NNP\n",
            "  (NP a/DT record/NN)\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  (NP power/NN)\n",
            "  in/IN\n",
            "  (NP the/DT mobile/JJ phone/NN)\n",
            "  (NP market/NN)\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  (NP the/DT company/NN)\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woOU0Jk9VZUV"
      },
      "source": [
        "**IOB Tagging** - Inside, Outside, Beginning of a chunk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU7fNQ0lVmyN",
        "outputId": "93d7a763-d62f-4e8e-c16e-97cafd39b99d"
      },
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "iob_tagged = tree2conlltags(cs)\n",
        "pprint(iob_tagged)\n",
        "\n",
        "#IOB TAGGING FORMATS https://www.geeksforgeeks.org/nlp-iob-tags/\n",
        "#B-NP : beginning of a noun phrase \n",
        "#I-NP : describes that the word is inside of the current noun phrase. \n",
        "#O : end of the sentence. \n",
        "#B-VP and I-VP : beginning and inside of a verb phrase."
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('European', 'JJ', 'O'),\n",
            " ('authorities', 'NNS', 'O'),\n",
            " ('fined', 'VBD', 'O'),\n",
            " ('Google', 'NNP', 'O'),\n",
            " ('a', 'DT', 'B-NP'),\n",
            " ('record', 'NN', 'I-NP'),\n",
            " ('$', '$', 'O'),\n",
            " ('5.1', 'CD', 'O'),\n",
            " ('billion', 'CD', 'O'),\n",
            " ('on', 'IN', 'O'),\n",
            " ('Wednesday', 'NNP', 'O'),\n",
            " ('for', 'IN', 'O'),\n",
            " ('abusing', 'VBG', 'O'),\n",
            " ('its', 'PRP$', 'O'),\n",
            " ('power', 'NN', 'B-NP'),\n",
            " ('in', 'IN', 'O'),\n",
            " ('the', 'DT', 'B-NP'),\n",
            " ('mobile', 'JJ', 'I-NP'),\n",
            " ('phone', 'NN', 'I-NP'),\n",
            " ('market', 'NN', 'B-NP'),\n",
            " ('and', 'CC', 'O'),\n",
            " ('ordered', 'VBD', 'O'),\n",
            " ('the', 'DT', 'B-NP'),\n",
            " ('company', 'NN', 'I-NP'),\n",
            " ('to', 'TO', 'O'),\n",
            " ('alter', 'VB', 'O'),\n",
            " ('its', 'PRP$', 'O'),\n",
            " ('practices', 'NNS', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPZE3QJNW_Q2"
      },
      "source": [
        "**Recognize Named Entities using a Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsBGUHihXAfb",
        "outputId": "863f3fb6-7e43-4819-a464-67b45354c6eb"
      },
      "source": [
        "from nltk.chunk import ne_chunk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "ne_tree = ne_chunk(pos_tag(word_tokenize(ex)))\n",
        "print(ne_tree)\n",
        "##GOOLGE IS A PERSON"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "(S\n",
            "  (GPE European/JJ)\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  (PERSON Google/NNP)\n",
            "  a/DT\n",
            "  record/NN\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  power/NN\n",
            "  in/IN\n",
            "  the/DT\n",
            "  mobile/JJ\n",
            "  phone/NN\n",
            "  market/NN\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  the/DT\n",
            "  company/NN\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUGqskF3YGf5"
      },
      "source": [
        "#**2) Using SpaCy for Named Entity Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWmRVENFYG0-"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnG33LJBYHU6",
        "outputId": "e4908ad9-7d14-4f8d-f499-656aa6b1175e"
      },
      "source": [
        "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
        "pprint([(X.text, X.label_) for X in doc.ents])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('European', 'NORP'),\n",
            " ('Google', 'ORG'),\n",
            " ('$5.1 billion', 'MONEY'),\n",
            " ('Wednesday', 'DATE')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlNBfn1DYL6t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}